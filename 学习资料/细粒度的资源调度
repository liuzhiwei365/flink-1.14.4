


Part1 细粒度资源调度 的资源信息的设置与流转

1 在生成 StreamGraph的时候的资源设置

StreamGraphGenerator.generate
   会循环处理 transformations 列表
   StreamGraphGenerator.transform
         1.1 一方面, 会将共享槽位的 资源信息放入到StreamGraphGenerator类 的 slotSharingGroupResources 成员中

         // 从 transform 中 提取槽位共享组信息;然后再从槽位共享组 提取资源设置,并且资源设置封装成ResourceProfile,
         // 放入到StreamGraphGenerator类 的 slotSharingGroupResources 成员中
         slotSharingGroupResources.compute(
               slotSharingGroup.getName(),
               (name, profile) -> {
                   if (profile == null) {
                       // 创建ResourceProfile对象
                       return ResourceProfile.fromResourceSpec(
                               resourceSpec, MemorySize.ZERO);
                   } else if (!ResourceProfile.fromResourceSpec(
                                   resourceSpec, MemorySize.ZERO)
                           .equals(profile)) {
                       throw new IllegalArgumentException(
                               "The slot sharing group "
                                       + slotSharingGroup.getName()
                                       + " has been configured with two different resource spec.");
                   } else {
                       return profile;
                   }
              });
         1.2 另外一方面 ,会将共享槽位组 的名称设置给相应的 StreamNode
           StreamGraphGenerator.translate
           // 自己没有配置,就拿上游的 共享槽位名 , 上游也没有 就用默认的, 该槽位名后续会被封装进入 StreamNode
           final String slotSharingGroup =
                   determineSlotSharingGroup(
                         transform.getSlotSharingGroup().isPresent()
                             ? transform.getSlotSharingGroup().get().getName()
                             : null,
                            allInputIds.stream()
                           .flatMap(Collection::stream)
                           .collect(Collectors.toList()));


2 在StreamGraph变成JobGraph的时候设置槽位 的 调用栈：

    StreamingJobGraphGenerator.createJobGraph()
        StreamingJobGraphGenerator.setSlotSharingAndCoLocation
            StreamingJobGraphGenerator.setSlotSharing
            会循环遍历所有的JobVertex, 给每个JobVertex 设置 槽位共享组, 并且给槽位共享组设置 ResourceProfile
                JobVertex.setSlotSharingGroup 和 SlotSharingGroup.setResourceProfile


3 在JobGraph 变成 ExecutionGraph的时候调用栈:

JobMasterServiceLeadershipRunner.createNewJobMasterServiceProcess
DefaultJobMasterServiceProcessFactory.create
DefaultJobMasterServiceProcess.DefaultJobMasterServiceProcess 构造方法
DefaultJobMasterServiceFactory.createJobMasterService
DefaultJobMasterServiceFactory.internalCreateJobMasterService
JobMaster构造方法
JobMaster.createScheduler
    DefaultSlotPoolServiceSchedulerFactory.createScheduler
        3.1 DefaultSchedulerFactory.createInstance
            DefaultScheduler 构造方法
            父类 SchedulerBase.SchedulerBase 构造方法
                 SchedulerBase.createAndRestoreExecutionGraph
                     DefaultExecutionGraphFactory.createAndRestoreExecutionGraph
                     DefaultExecutionGraphBuilder.buildGraph
                        DefaultExecutionGraph.attachJobGraph
                        会循环遍历所有的 JobVertex, 然后构建 ExecutionJobVertex 对象
                        ExecutionJobVertex 构造方法
                        会提取JobVertex的相关成员来给 ExecutionJobVertex 的 slotSharingGroup成员赋值 （内部包含ResourceProfile资源信息）


        或者
        3.2 AdaptiveSchedulerFactory.createInstance
            AdaptiveScheduler构造方法
               在构造方法中会注册一个监听器,当有新的资源来时, 触发调用 AdaptiveScheduler.newResourcesAvailable 方法 来处理动态扩容

            DefaultExecutionGraphFactory.createAndRestoreExecutionGraph
            DefaultExecutionGraphBuilder.buildGraph
总结：
    对于DefaultScheduler 调度器而言, 在创建调度器的时候就会去构建 ExecutionGraph
    而对于 AdaptiveScheduler 调度器而言,在启动调度器后才会去 依情况构建  ExecutionGraph

4 设置 cluster.fine-grained-resource-management.enabled为true开启细粒度资源分配
  细粒度资源分配使用的实现类是FineGrainedSlotManager

  在 flink 内部的资源管理器启动的时候

  ResourceManagerServiceImpl.start
     ...
     ResourceManagerServiceImpl.grantLeadership （理由请参见 flink组件高可用章节 ）
        ResourceManagerServiceImpl.startNewLeaderResourceManager
           4.1  先创建 ResourceMananger
                ResourceManagerFactory.createResourceManager(ResourceManagerProcessContext, UUID, ResourceID)
                  ResourceManagerFactory.createResourceManager
                    ResourceManagerFactory.createResourceManagerRuntimeServices
                      ResourceManagerRuntimeServices.fromConfiguration
                       4.1.1 先创建 SlotManager
                               会根据配置 创建 FineGrainedSlotManager 或者 DeclarativeSlotManager
                       4.1.2 再创建 JobLeaderIdService
                               维护所有作业的  "选举成为leader的" JobMasterId

                       4.1.3 两者封装成为 ResourceManagerRuntimeServices 对象 （会作为 ResourceMananger的 重要成员变量）
           4.2   再启动 ResourceMananger
                ResourceManagerServiceImpl.startResourceManagerIfIsLeader
                   resourceManager.start()
                   会调用 ResourceManager.onStart （ResourceManager 是RpcEndpoint 的子类, 请参见 RpcEndpoint 体系文档）
                   ResourceManager.startResourceManagerServices
                      4.2.1 启动 JobLeaderIdService
                      4.2.2 注册 Metrics
                      4.2.3 启动 SlotManager
                      4.2.4 调用 ResourceManager.initialize 方法初始化 ,有两类实现
                           4.2.4.1  使用外部资源调度
                                    ActiveResourceManager.initialize
                                    AbstractResourceManagerDriver.initialize
                                        又有k8s 和 yarn 两种实现
                                        4.2.4.1.1  KubernetesResourceManagerDriver.initializeInternal
                                        4.2.4.1.2  YarnResourceManagerDriver.initializeInternal
                           4.2.4.1  不使用外部资源调度










